- src/util depends on src/tensor (e.g. random_noise.hpp)
- src/file depends on src/util (e.g. on logger)

- finish the synthetic task:
	- more shapes: filled & hollow triangles, vertical & diagonal crosses

- update the test program to evaluate the optimizers to call directly trainer-based functions:
	- use the trainers' implementation
	- use the synthetic dataset	

	- sort the optimization results by training log-loss, training error, validation error and elapsed time

- nicer way to specify colors than using the current array:
set style line 1 linecolor rgb '#0060ad' linetype 1 linewidth 2  # blue
set style line 2 linecolor rgb '#dd181f' linetype 1 linewidth 2  # red

- augment training samples (to reduce overfitting):
	- new parameter to all tasks: "noisy=off/on"

	- salt & pepper noise (vary the percentage)
	- translation, scale, various deformations

	- ncv_info_task should also be updated to display the noisy training samples

- check the speed improvement if using floats instead of doubles for training MLP0

- more experiments with floats instead of doubles:
	- check the impact on MLPs and convolutions
	- are the stochastic methods going to be faster?! (tons of gradient-based linear algebra)

- MAD with index shifts (may speed-up corr2d)

- test program to assess the speed of the 3D convolution/correlation operations

- faster convolution:
 	- build a toeplitz matrix, then the convolution becomes a matrix multiplication:
		- http://en.wikipedia.org/wiki/Toeplitz_matrix

        - check if any improvement if using a 3D convolution    

- GTSD dataset support (after 0.1 release):
	- create both classification and detection tasks
	- build an object detector

- finish the training scripts for other datasets (CIFAR-10, CIFAR-100, SVHN, NORB, STL)

- unsupervised learning (after 0.1 release): 
	- unsupervised training:
		- new loss (without the output layer): a single output should have a much larger value magnitude than the others 
			(e.g. learn to disintangle the variation modes)
		- than train the output layer with the annotated samples

- reconstruction regularization (after 0.1 release):
	- for linear & convolution layers -> reuse parameters to easily reconstruct the input

- feature visualization & image generation (after 0.1 release)

- thread_loop with states should use std::future to obtain the returned values (e.g. gradient & loss value)
	

