- BUG:
	- line-search for lbfgs is quite slow for stl10

* sample_t: always store as rgba_image_t, but provide function to copy to vector_t (3 x rows x cols), ::n_rows(), ::n_cols(), ::n_inputs() = 3xrowsxcols

- speed-up compilation


* optimize: line-search policy (try until eps, try 16 times)

* default line-search parameters in the lbfgs, gd, cgd functions
* (iters + eps) as parameters to the linear model, update the command line
* options to problem_t to print the current step (after line-search): fx, gradient

* check how fast is to run a 8x8 16-filter convolution with 4-8 layers for a 40x40 100K images
(if fast -> may store the samples as RGBA patches, model_t::process(rgba_image, x, y))

- train/test models:
	- test the training script
	- make cmake work with Qt5 modules

	- FASTER linear training!
		- more efficient: v * u.transpose()

	- experimentation script: train linear models on all datasets (256, 1e-5)

	- regularization: l2, symmetry
	- could add options to filter the input: e.g. smoothing, normalization, contrast equalization

- small ui application to visualize task images

- faster RGB to CIELab transform (goal: 1s single-thread version of the color testing program)

- add other datasets:
	- INRIA car and person datasets
	- NORB, inria pedestrian detection, inria human detection, dymlerchrysler human detection, face detection, PASCALVoc2011, CALTECH101...

- autoencoders: how to generate samples ?!

- may revive/improve the bootstrapping idea:
        - also bootstrap the background of the images containing faces
                => many billions of samples (may require removing some profile faces or some animals 
                        that look very much like frontal faces)

