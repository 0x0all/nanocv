- faster ::backward() -> almost 4 times slower than ::forward()
- check if the convolution layers can use fewer buffers (e.g. do not store xdata and update directly the output buffers)
- faster convolution layer - reduce the number of loops - concatenate convolutions?!
       
- (soft) max-pooling layer: parameter = radius in pixels
        - e.g. rad = 2 -> reduces the feature maps by 2

- augment the training dataset with random translations and rotations (only for the stochastic trainer) + test program (given image, save N random translations and rotations of a given pixel radius)

- thread_loop with states should use std::future to obtain the returned values (e.g. gradient & loss value)
	
- svhn decoding:
	- the sections are not decoded correctly: 
		- the data type of the last two sections is not valid
		- the number of bytes in the last section is not valid

- implement other training methods for the convolution network:
	- regularization: variational learning (like in ebbbost)
        - auto-encoding: using the unlabeled data (could also try with all samples)
        - train a single layer at a time
        - regularization: l2, symmetry
        - could use genetic algorithms and encode a convolution matrix using e.g. 16 possible values, can impose symmetry-like constrains 
        - could add options to filter the input: e.g. smoothing, normalization, contrast equalization

        - autoencoders: how to generate samples ?!

- add other datasets:
        - INRIA car and person datasets
        - NORB, inria pedestrian detection, inria human detection, dymlerchrysler human detection, face detection, PASCALVoc2011, CALTECH101...

- make install:
	- also copy the headers 


